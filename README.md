# Data transformations with Python
This is a collection of _Python_ jobs that are supposed to transform data.
These jobs are using _PySpark_ to process larger volumes of data and are supposed to run on a _Spark_ cluster (via `spark-submit`).

## Pre-requisites
Please make sure you have the following installed and can run them
* Docker Desktop
* Visual Studio Code

## Install Remote Container extension for Visual Studio Code
* In VS Code's top menu: View > Extensions, install the following Extension on VS Code:
Remote - Containers (author: Microsoft)
